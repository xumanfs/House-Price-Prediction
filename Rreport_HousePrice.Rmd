---
title: "House Price Prediction"
author: "XuMan"
date: "2020/6/20"
output: 
  html_document:
    toc : TRUE
    number_sections: true
---

# Executive summary

In this report, I try to predict sale price of houses in Ames, Iowa based on a series of variables concerning the house's size, quality, facilities and information about the deal. The prediction model can be useful for both dealers and investors of real estate by helping them to decide on a fair price based on large data analysis.

## Goal of the project

The aim of the project is to create a machine learning algorithm that predicts the sale prices of each house. Performance of the algorithm is evaluated by Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price, which is defined as:
$$ RMSE = \sqrt{\frac{1}{N}\displaystyle\sum_{u,i} [log(\hat{y}_{u,i})-log(y_{u,i})]^{2}} $$

Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally. 

## Data set description

First we read the train and test data set into the environment.

```{r read_file}
train_set <- read.csv("/Users/xuman/ds_projects/House-Price-Prediction/house-prices-advanced-regression-techniques/train.csv")
test_set <- read.csv("/Users/xuman/ds_projects/House-Price-Prediction/house-prices-advanced-regression-techniques/test.csv")
```

The train set is in tidy form with `r dim(train_set)[1]` rows and `r dim(train_set)[2]` columns. The columns include Id, SalePrice and 79 predictors. Detailed definition of the variables can be found on Kaggle.com.

The test set is of similar structure with the train set. It has `r dim(test_set)[1]` rows and `r dim(test_set)[2]` columns, without SalePrice.

I construct a full data set for data cleaning and exploration.

```{r construct_full_dataset}
test_set$SalePrice <- NA
dataset <- rbind(train_set, test_set)
```

## Key methods

The main challenge in this project is to organize the 79 explanatory variables describing basically every aspect of residential homes, with missing values in them. 

The data set is carefully cleaned. Then I construct predictive models using 3 methods that are suitable for dataset with many predictors: random forest(RF), least absolute shrinkage and selection operator(Lasso) and gradient boosting decision tree(GBDT). A stacked model is computed based on the average of the predictions of the three models. The RMSE-scores of the models are compared.

# Dataset exploration

## Preparation

Load the packages used in later analysis and prepare the settings.

```{r load_packages, collapse=TRUE, warning=FALSE}
options(scipen=100)

library(tidyverse)
library(caret)
library(Rborist)
library(FNN)
library(glmnet)
library(gbm)
library(moments)
library(corrplot)
```

## Clean the dataset

In this section, we deal with the missing values. The first step is to find the variables with missing data.

```{r variables_with_missing_data}
perct_na <- sort(desc(apply(dataset, 2, function(x) sum(is.na(x))/nrow(dataset)*100)))
perct_na[perct_na < 0]
```

There are `r length(perct_na[perct_na < 0])-1` variables with missing data. I look into their definition and structure one by one and group them into 5 strategies.

### Remove

Some variables("PoolQC", "MiscFeature", "Alley", "Fence", "FireplaceQu") have more than 20% of missing values. I simply remove them because there are too many missing values.

As for the variable "Utilities", since 2916 houses are "AllPub" and only 1 house is "NoSeWa", if we impute ‘AllPub’ for the 2 NAs, the variable will be useless for prediction because of lack of variation. So "Utilities" is also removed.

### Fill with "None"

There are NAs in "GarageType","GarageQual","GarageCond","GarageFinish", "GarageYrBlt", "BsmtExposure","BsmtFinType2","BsmtQual","BsmtCond","BsmtFinType1", "MasVnrType" because the houses have no garage, basement or Masonry veneer. The NAs are filled with "None", which is also a factor that already exists in the variables.

### Fill with the most frequent factor

NAs in "Electrical", "MSZoning" are filled with the most frequent type.

### Fill with 0

NAs in "MasVnrArea", "BsmtFullBath", "BsmtHalfBath", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "GarageCars", "GarageArea" are filled with 0.

### Fill with guessed data

NAs in "GarageYrBlt" are filled with the year the house was built "YearBuilt". NAs in "LotFrontage" are filled with the median of available values.

```{r deal_with_NAs}
var_names_na_to_none <- c("GarageType","GarageQual","GarageCond","GarageFinish", "BsmtExposure","BsmtFinType2","BsmtQual","BsmtCond","BsmtFinType1", "MasVnrType")
var_names_na_to_zero <- c("MasVnrArea", "BsmtFullBath", "BsmtHalfBath", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "GarageCars", "GarageArea")
fill_with_highest_req <- c("MSZoning", "Functional", "Exterior1st", "Exterior2nd", "KitchenQual", "Electrical", "SaleType")

dataset_2 <- dataset %>%
  select(-c("PoolQC", "MiscFeature", "Alley", "Fence", "FireplaceQu", "Utilities")) %>%
  mutate_at(var_names_na_to_none, function(x) ifelse(is.na(x), "None", x)) %>%
  mutate(GarageYrBlt = ifelse(is.na(GarageYrBlt), YearBuilt, GarageYrBlt)) %>%
  mutate(LotFrontage = ifelse(is.na(LotFrontage), median(LotFrontage, na.rm = TRUE), LotFrontage)) %>%
  mutate_at(var_names_na_to_zero, function(x) ifelse(is.na(x), 0, x)) %>%
  mutate_at(fill_with_highest_req, function(x) ifelse(is.na(x), levels(x)[which.max(table(x))], x))
```
  
Now let's verify that there is no NA left in the new data set.

```{r no_na_left}
sapply(dataset_2, function(x) sum(is.na(x)))
```

## Preprocessing for analysis

### Class of variables

We can see that some variables should be defined as class factor, but are now of class character.

```{r dataset_class}
sapply(dataset_2, class)
```

So we need to change their class into factor.

```{r character_to_factor}
var_names_to_type_factor <- c("MSSubClass", "MSZoning", "OverallQual", "OverallCond", "YearBuilt", "YearRemodAdd", "Exterior1st", "Exterior2nd", "MoSold", "YrSold", "MasVnrType", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2", "BsmtQual", "Electrical", "KitchenQual", "Functional", "GarageType", "GarageYrBlt", "GarageFinish", "GarageQual", "GarageCond", "SaleType")

dataset_3 <- dataset_2 %>% mutate_at(var_names_to_type_factor, function(x) as.factor(x))
```

Now let's verify that all variables are of the right class.

```{r verify_class}
sapply(dataset_3, class)
```

### Normalize the numeric variables

If we take a look at the dependent variable "SalePrice", we can find that the histogram is not symmetrical so SalePrice is not of normal distribution. We can clearly see that there are more expensive housed than cheap ones.

```{r saleprice_distribution, warning=FALSE, message=FALSE}
dataset_3 %>% ggplot(aes(SalePrice)) +
  geom_histogram(color = "white")
```

We use skewness to measure the data set's degree  of deviation from a symmetrical distribution.

```{r skewness_saleprice}
skewness(dataset_3$SalePrice, na.rm = TRUE)
```

In order to fix the skewness, we take the log for SalePrice. Now we can see that the skewness is closer to 0.

```{r skewness_log_saleprice}
skewness(log(dataset_3$SalePrice), na.rm = TRUE)
```

There are other numeric predictors that also need to be normalized. I calculate the skewness of the predictors and find the ones with skewness larger than 0.8 or smaller than -0.8.

```{r vars_to_normalize}
index_numeric <- which(sapply(dataset_3, is.numeric))

numeric_predictors <- dataset_3[index_numeric]
numeric_predictors <- numeric_predictors[, -which(colnames(numeric_predictors) %in% c("Id","SalePrice"))]
predictors_skewness <- sapply(numeric_predictors, skewness)
vars_to_normalize <- names(predictors_skewness[abs(predictors_skewness) > 0.8])
vars_to_normalize
```

I fix the skewness by taking log+1 for the predictors.

```{r normalize_predictors}
dataset_4 <- dataset_3 %>%
  mutate_at(vars_to_normalize, function(x) log(x+1))

train_set_4 <- dataset_4[!is.na(dataset_4$SalePrice), ]
test_set_4 <- dataset_4[is.na(dataset_4$SalePrice), ]
```

# Analysis

Predictive models are built using random forest, Lasso, and GBDT algorithm. A stacked model is also built using the average of the previous three models.

## Random Forest

```{r rf_model, warning=FALSE}

control <- trainControl(method = "cv", number = 5, verboseIter = FALSE)
set.seed(40)
train_rf <- train(log(SalePrice)~ .-Id, data = train_set_4,  method = "Rborist",  trControl = control,  tuneGrid = data.frame(predFixed = 2, minNode = c(3, 5, 10, 25, 50)))

y_train <- log(train_set_4$SalePrice)
x_train <- train_set_4 %>% select(-c("Id", "SalePrice"))
fit_rf <- Rborist(x_train, y_train, minNode = 3)

x_test <- test_set_4 %>% select(-c("Id", "SalePrice"))
y_predict_rf <- predict(fit_rf, x_test)
y_hat_rf <- exp(y_predict_rf[["yPred"]])

sub_rf <- data.frame(Id = test_set$Id, SalePrice = y_hat_rf)
write.csv(sub_rf, file = "sub_rf_2.csv", row.names = FALSE)
```

## Lasso

```{r lasso_model, warning=FALSE}
x_train_lasso <- model.matrix(as.formula( log(SalePrice)~ .-Id ), train_set_4)

set.seed(40)
fit_lasso <- cv.glmnet(x_train_lasso, y_train, alpha=1)
test_set_4$SalePrice <- 1
x_test_lasso <- model.matrix(as.formula( log(SalePrice)~ .-Id ), test_set_4)
y_predict_lasso <- predict(fit_lasso, newx = x_test_lasso, s = "lambda.min")
y_hat_lasso <- exp(as.numeric(y_predict_lasso))

sub_lasso <- data.frame(Id = test_set$Id, SalePrice = y_hat_lasso)
write.csv(sub_lasso, file = "sub_lasso.csv", row.names = FALSE)
```

## GBDT

```{r gbdt_model, warning=FALSE, message=FALSE, results="hide"}
train_gbdt <- train(log(SalePrice)~ .-Id, data = train_set_4,  method = "gbm",  trControl = control)
y_predict_gbdt <- predict(train_gbdt, test_set_4)
y_hat_gbdt <- exp(y_predict_gbdt)
sub_gbdt <- data.frame(Id = test_set$Id, SalePrice = y_hat_gbdt)
write.csv(sub_gbdt, file = "sub_gbdt.csv", row.names = FALSE)
```

## Average the random forest, lasso and gbdt model

```{r stacked_model, warning=FALSE}
y_predict_rf_lasso_gbdt <- (y_hat_rf + y_hat_lasso + y_hat_gbdt)/3
sub_rf_lasso_gbdt <- data.frame(Id = test_set$Id, SalePrice = y_predict_rf_lasso_gbdt)
write.csv(sub_rf_lasso_gbdt, file = "sub_rf_lasso_gbdt.csv", row.names = FALSE)
```

# Results

We can see the result of the four models by submitting our predictions to the website. The result is as follows.

```{r train_set_head, echo=FALSE}
knitr::kable(data.frame(method = c("RF", "Lasso", "GBDT", "Stacked"), RMSE = c(0.21088, 0.13506, 0.14421, 0.14675)))
```

The Lasso model generates the most precise prediction.

# Conclusion

In the report, four models are built using different algorithms and their performances are compared. We carefully clean the data set and organize it to fit with the models.

I believe the result can be further improved by 3 methods: 1)better selection of model parameters; 2) feature engineering; 3) try other algorithms.
